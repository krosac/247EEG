{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "EE_247_final_project_inception.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiGI0306sEJX",
        "colab_type": "code",
        "outputId": "b15640bf-b28a-4a40-ac92-5c2638230465",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "%cd /content/drive/My Drive/ECE 247/project/project"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/ECE 247/project/project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vy7XBkpnfueF",
        "colab_type": "code",
        "outputId": "855d4359-4331-4617-a80e-33dbedfe27cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwjCfkAvljYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# for creating validation set\n",
        "from sklearn.model_selection import train_test_split\n",
        "# for evaluating the model\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout, ELU\n",
        "from torch.optim import Adam, SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzjOal5dljYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = np.load(\"X_test.npy\")\n",
        "y_test = np.load(\"y_test.npy\")\n",
        "person_train_valid = np.load(\"person_train_valid.npy\")\n",
        "X_train_valid = np.load(\"X_train_valid.npy\")\n",
        "y_train_valid = np.load(\"y_train_valid.npy\")\n",
        "person_test = np.load(\"person_test.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pNlBDcfljYP",
        "colab_type": "code",
        "outputId": "aef8251d-c247-4c66-cb79-d5050600ab30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
        "print ('Test data shape: {}'.format(X_test.shape))\n",
        "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
        "print ('Test target shape: {}'.format(y_test.shape))\n",
        "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
        "print ('Person test shape: {}'.format(person_test.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training/Valid data shape: (2115, 22, 1000)\n",
            "Test data shape: (443, 22, 1000)\n",
            "Training/Valid target shape: (2115,)\n",
            "Test target shape: (443,)\n",
            "Person train/valid shape: (2115, 1)\n",
            "Person test shape: (443, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1OTW12fljYT",
        "colab_type": "code",
        "outputId": "efe9409f-bbde-4429-90d1-5d7bf23d50fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# change dimensions\n",
        " X_train_valid = X_train_valid[:, np.newaxis, :, :]\n",
        " X_test = X_test[:, np.newaxis, :, :]\n",
        "# # create labels \n",
        " y_train_valid = y_train_valid - 769\n",
        " y_test = y_test -769\n",
        "\n",
        "# split training and validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_valid, y_train_valid, test_size = 0.1)\n",
        "data = []\n",
        "(X_train.shape, y_train.shape), (X_val.shape, y_val.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(((1903, 1, 22, 1000), (1903,)), ((212, 1, 22, 1000), (212,)))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgNpsbBkljYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# transform to torch tensor\n",
        "X_train = torch.from_numpy(X_train)\n",
        "y_train = torch.from_numpy(y_train)\n",
        "\n",
        "X_val = torch.from_numpy(X_val)\n",
        "y_val = torch.from_numpy(y_val)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9ms47EOMs_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# process the data in batches for training\n",
        "batch_size = 100\n",
        "train_data = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGgOfzkJtj6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.is_available()\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device('cuda:0' if use_cuda else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkKGke9JJxGw",
        "colab_type": "text"
      },
      "source": [
        "The naive CNN above seems to overfit the data. Next let's try GRU mentioned in https://arxiv.org/pdf/1802.00308.pdf\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9xecE_dKDAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net_lstm(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_lstm, self).__init__()\n",
        "\n",
        "        self.branch1x1 = Sequential(\n",
        "                          nn.Conv2d(in_channels=1, out_channels=12, kernel_size=1), # 1\n",
        "                          nn.BatchNorm2d(12),\n",
        "                          nn.ELU(inplace=True),\n",
        "                          nn.Dropout(0.4)\n",
        "        )\n",
        "\n",
        "        self.branch1x3 = Sequential(\n",
        "                          nn.Conv2d(in_channels=1, out_channels=12, kernel_size=1),\n",
        "                          nn.BatchNorm2d(12),\n",
        "                          nn.ELU(inplace=True),\n",
        "                          nn.Dropout(0.4),\n",
        "                          nn.Conv2d(in_channels=12, out_channels=12, kernel_size=(1,3),padding=(0, 1)), \n",
        "                          nn.BatchNorm2d(12),\n",
        "                          nn.ELU(inplace=True),\n",
        "                          nn.Dropout(0.4),\n",
        "\n",
        "        )\n",
        "        self.branch1x5 = Sequential(\n",
        "                          nn.Conv2d(in_channels=1, out_channels=12, kernel_size=1),\n",
        "                          nn.BatchNorm2d(12),\n",
        "                          nn.ELU(inplace=True),\n",
        "                          nn.Dropout(0.4),\n",
        "                          nn.Conv2d(in_channels=12, out_channels=12, kernel_size=(1,5),padding=(0, 2)), \n",
        "                          nn.BatchNorm2d(12),\n",
        "                          nn.ELU(inplace=True),\n",
        "                          nn.Dropout(0.4)\n",
        "        )\n",
        "        self.branch_pool = Sequential(\n",
        "            nn.MaxPool2d(kernel_size=(1,3), stride=(1,1),padding=(0, 1)),\n",
        "            nn.Conv2d(in_channels=1, out_channels=12, kernel_size=1),\n",
        "            nn.BatchNorm2d(12),\n",
        "            nn.ELU(inplace=True),\n",
        "            nn.Dropout(0.4)\n",
        "        )\n",
        "        #22 x 1000 x 48\n",
        "\n",
        "        #maxpool2d\n",
        "        self.MaxPool2d = nn.MaxPool2d(kernel_size=(1,2), stride=(1,2))\n",
        "        #22 x 500 x 48\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "        \"\"\"self.branch2_1x2 = Sequential(\n",
        "                          nn.Conv2d(in_channels=48, out_channels=12, kernel_size=(1,2),stride=(1,2),padding=(0, 0)),\n",
        "                          nn.BatchNorm2d(12),\n",
        "                          nn.Dropout(0.1)\n",
        "        )\n",
        "        self.branch2_1x4 = Sequential(\n",
        "                          nn.Conv2d(in_channels=48, out_channels=12, kernel_size=(1,4),stride=(1,2),padding=(0, 1)),\n",
        "                          nn.BatchNorm2d(12),\n",
        "                          nn.Dropout(0.1)\n",
        "        )\n",
        "        self.branch2_1x8 = Sequential(\n",
        "                          nn.Conv2d(in_channels=48, out_channels=12, kernel_size=(1,8),stride=(1,2),padding=(0, 3)),\n",
        "                          nn.BatchNorm2d(12),\n",
        "                          nn.Dropout(0.1)\n",
        "        )\n",
        "        self.branch_pool2 = Sequential(\n",
        "            nn.MaxPool2d(kernel_size=(1,2), stride=(1,2),padding=(0, 0)),\n",
        "            nn.Conv2d(in_channels=48, out_channels=12, kernel_size=1),\n",
        "            nn.BatchNorm2d(12),\n",
        "            nn.Dropout(0.1)\n",
        "        )#11x 250 x 48\"\"\"\n",
        "        \n",
        "        \n",
        "\n",
        "        \"\"\"self.branch3_2x2 = Sequential(\n",
        "                          nn.Conv2d(in_channels=48, out_channels=24, kernel_size=(2,2),stride=(2,2),padding=(0, 0)),\n",
        "                          nn.BatchNorm2d(24),\n",
        "                          nn.Dropout(0.2)\n",
        "        )\n",
        "        self.branch3_2x4 = Sequential(\n",
        "                          nn.Conv2d(in_channels=48, out_channels=24, kernel_size=(2,4),stride=(2,2),padding=(0, 1)),\n",
        "                          nn.BatchNorm2d(24),\n",
        "                          nn.Dropout(0.2)\n",
        "        )\n",
        "        self.branch3_2x8 = Sequential(\n",
        "                          nn.Conv2d(in_channels=48, out_channels=24, kernel_size=(2,8),stride=(2,2),padding=(0, 3)),\n",
        "                          nn.BatchNorm2d(24),\n",
        "                          nn.Dropout(0.2)\n",
        "        )\n",
        "                          \n",
        "        self.branch_pool3 = Sequential(\n",
        "            nn.MaxPool2d(kernel_size=(2,2), stride=(2,2),padding=(0, 0)),\n",
        "            nn.Conv2d(in_channels=48, out_channels=24, kernel_size=1),\n",
        "            nn.BatchNorm2d(24),\n",
        "            nn.Dropout(0.2)\n",
        "            )\"\"\"#11x 125 x 96\n",
        "        \n",
        "        \n",
        "        self.conv1 =  Sequential (\n",
        "                          nn.Conv2d(in_channels=48, out_channels=64, kernel_size=(2,8),stride=(2,2),padding=(0, 3)),\n",
        "                          nn.BatchNorm2d(64),\n",
        "                          nn.ELU(inplace=True),\n",
        "                          nn.MaxPool2d(kernel_size=(1,2), stride=(1,2)),\n",
        "                          nn.Dropout(0.4)\n",
        "        ) #11x 125 x 64\n",
        "        \n",
        "        self.conv2 = Sequential (\n",
        "                          nn.Conv2d(in_channels=64, out_channels=96, kernel_size=(1,8), stride=(1,1)),\n",
        "                          nn.BatchNorm2d(96),\n",
        "                          nn.ELU(inplace=True),\n",
        "                          nn.MaxPool2d(kernel_size=(1,6), stride=(1,2)),\n",
        "                          nn.Dropout(0.4)\n",
        "        )#11x 57 x 96\n",
        "\n",
        "        self.MaxPool2d2 = nn.MaxPool2d(kernel_size=(1,3), stride=(1,2))\n",
        "        #11x 62 x 96\n",
        "\n",
        "\n",
        "        self.conv4 = Sequential (\n",
        "                          nn.Conv2d(in_channels=96, out_channels=128, kernel_size=(2,4), stride=(1,2)),\n",
        "                          nn.BatchNorm2d(128),\n",
        "                          nn.ELU(inplace=True), \n",
        "                          nn.MaxPool2d(kernel_size=(1,3), stride=(1,2)),\n",
        "                          nn.Dropout(0.4)\n",
        "        )#10 x 13 x 128\n",
        "       \n",
        "        \n",
        "        self.conv5 = Sequential(\n",
        "                          nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,4), stride=(1,3)),\n",
        "                          nn.BatchNorm2d(256),\n",
        "                          nn.ELU(inplace=True),\n",
        "                          nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)),\n",
        "                          nn.Dropout(0.4)\n",
        "        )\n",
        "        #4 x 2 x 256\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.lstm1 = nn.LSTM(256*8, 128, 1, batch_first=True, bidirectional=True)\n",
        "        self.lstm2 = nn.LSTM(256, 64, 1, batch_first=True, bidirectional=True)\n",
        "        self.lstm3 = nn.LSTM(128, 32, 1, batch_first=True, bidirectional=True)\n",
        "       # self.lstm4 = nn.LSTM(64, 32, 1, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(in_features=64,  out_features=4)\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.softmax = nn.Softmax()\n",
        "    def forward(self, X):\n",
        "        x_b11 = self.branch1x1(X)\n",
        "        #print(x_b1.shape)\n",
        "        x_b12 = self.branch1x3(X)\n",
        "        #print(x_b2.shape)\n",
        "        x_b13 = self.branch1x5(X)\n",
        "        #print(x_b3.shape)\n",
        "        x_b14 = self.branch_pool(X)\n",
        "        x = torch.cat([x_b11,x_b12,x_b13, x_b14],dim=1)\n",
        "        #print(x.shape)\n",
        "        #x = self.conv1(x)\n",
        "       # print(x.shape)\n",
        "        x = self.MaxPool2d(x) \n",
        "\n",
        "        #x_b21 = self.branch2_1x2(x)\n",
        "        #print(x_b21.shape)\n",
        "        #x_b22 = self.branch2_1x4(x)\n",
        "        #print(x_b22.shape)\n",
        "       # x_b23 = self.branch2_1x8(x)\n",
        "       # print(x_b23.shape)\n",
        "        #x_b24 = self.branch_pool2(x)\n",
        "        #print(x_b24.shape)\n",
        "       # x = torch.cat([x_b21,x_b22,x_b23, x_b24],dim=1)\n",
        "       # print(x.shape)\n",
        "\n",
        "        #x_b31 = self.branch3_2x2(x)\n",
        "        #print(x_b1.shape)\n",
        "        #x_b32 = self.branch3_2x4(x)\n",
        "        #print(x_b2.shape)\n",
        "        #x_b33 = self.branch3_2x8(x)\n",
        "        #print(x_b3.shape)\n",
        "        #x_b34 = self.branch_pool3(x)\n",
        "        #x = torch.cat([x_b31,x_b32,x_b33, x_b34],dim=1)\n",
        "        #print(x.shape)\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        #print(x.shape)\n",
        "        x = self.conv2(x)\n",
        "        #print(x.shape)\n",
        "        #x = self.MaxPool2d2(x)\n",
        "        #print(x.shape)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        #print(x.shape)\n",
        "        x = self.conv5(x)\n",
        "        #print(x.shape)\n",
        "        x = x.permute(0,3,1,2) # important! -- without <50% 128x2x12->12x128x2\n",
        "        #print(x.shape)\n",
        "        x = x.reshape([-1,1,256*8])\n",
        "        #print(x.shape)\n",
        "        x, _ = self.lstm1(x)\n",
        "        x, _ = self.lstm2(x)\n",
        "        x, _ = self.lstm3(x)\n",
        "        #x, _ = self.lstm4(x)\n",
        "        x = x.squeeze()\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e446e205-99e6-4653-d4eb-a7ecfda3fc44",
        "id": "2owwq0FepVCH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# defining the model\n",
        "model = Net_lstm()\n",
        "model = model.float()\n",
        "# # defining the optimizer\n",
        "optimizer = Adam(model.parameters(), lr=0.001)\n",
        "# # defining the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# # checking if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "     model = model.cuda()\n",
        "     criterion = criterion.cuda()\n",
        "\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net_lstm(\n",
            "  (branch1x1): Sequential(\n",
            "    (0): Conv2d(1, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ELU(alpha=1.0, inplace=True)\n",
            "    (3): Dropout(p=0.4, inplace=False)\n",
            "  )\n",
            "  (branch1x3): Sequential(\n",
            "    (0): Conv2d(1, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ELU(alpha=1.0, inplace=True)\n",
            "    (3): Dropout(p=0.4, inplace=False)\n",
            "    (4): Conv2d(12, 12, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
            "    (5): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ELU(alpha=1.0, inplace=True)\n",
            "    (7): Dropout(p=0.4, inplace=False)\n",
            "  )\n",
            "  (branch1x5): Sequential(\n",
            "    (0): Conv2d(1, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ELU(alpha=1.0, inplace=True)\n",
            "    (3): Dropout(p=0.4, inplace=False)\n",
            "    (4): Conv2d(12, 12, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n",
            "    (5): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ELU(alpha=1.0, inplace=True)\n",
            "    (7): Dropout(p=0.4, inplace=False)\n",
            "  )\n",
            "  (branch_pool): Sequential(\n",
            "    (0): MaxPool2d(kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), dilation=1, ceil_mode=False)\n",
            "    (1): Conv2d(1, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): ELU(alpha=1.0, inplace=True)\n",
            "    (4): Dropout(p=0.4, inplace=False)\n",
            "  )\n",
            "  (MaxPool2d): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(48, 64, kernel_size=(2, 8), stride=(2, 2), padding=(0, 3))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ELU(alpha=1.0, inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Dropout(p=0.4, inplace=False)\n",
            "  )\n",
            "  (branch2_1x2): Sequential(\n",
            "    (0): Conv2d(48, 12, kernel_size=(1, 2), stride=(1, 2))\n",
            "    (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (branch2_1x4): Sequential(\n",
            "    (0): Conv2d(48, 12, kernel_size=(1, 4), stride=(1, 2), padding=(0, 1))\n",
            "    (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (branch2_1x8): Sequential(\n",
            "    (0): Conv2d(48, 12, kernel_size=(1, 8), stride=(1, 2), padding=(0, 3))\n",
            "    (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (branch_pool2): Sequential(\n",
            "    (0): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=(0, 0), dilation=1, ceil_mode=False)\n",
            "    (1): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(64, 96, kernel_size=(1, 8), stride=(1, 1))\n",
            "    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ELU(alpha=1.0, inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=(1, 6), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Dropout(p=0.4, inplace=False)\n",
            "  )\n",
            "  (branch3_2x2): Sequential(\n",
            "    (0): Conv2d(48, 24, kernel_size=(2, 2), stride=(2, 2))\n",
            "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "  )\n",
            "  (branch3_2x4): Sequential(\n",
            "    (0): Conv2d(48, 24, kernel_size=(2, 4), stride=(2, 2), padding=(0, 1))\n",
            "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "  )\n",
            "  (branch3_2x8): Sequential(\n",
            "    (0): Conv2d(48, 24, kernel_size=(2, 8), stride=(2, 2), padding=(0, 3))\n",
            "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): Dropout(p=0.2, inplace=False)\n",
            "  )\n",
            "  (branch_pool3): Sequential(\n",
            "    (0): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0), dilation=1, ceil_mode=False)\n",
            "    (1): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Dropout(p=0.2, inplace=False)\n",
            "  )\n",
            "  (MaxPool2d2): MaxPool2d(kernel_size=(1, 3), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(96, 128, kernel_size=(2, 4), stride=(1, 2))\n",
            "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ELU(alpha=1.0, inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=(1, 3), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Dropout(p=0.4, inplace=False)\n",
            "  )\n",
            "  (conv5): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(3, 4), stride=(1, 3))\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ELU(alpha=1.0, inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Dropout(p=0.4, inplace=False)\n",
            "  )\n",
            "  (flatten): Flatten()\n",
            "  (lstm1): LSTM(2048, 128, batch_first=True, bidirectional=True)\n",
            "  (lstm2): LSTM(256, 64, batch_first=True, bidirectional=True)\n",
            "  (lstm3): LSTM(128, 32, batch_first=True, bidirectional=True)\n",
            "  (fc): Linear(in_features=64, out_features=4, bias=True)\n",
            "  (dropout): Dropout(p=0.4, inplace=False)\n",
            "  (softmax): Softmax(dim=None)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kvo8E1apZXC",
        "colab_type": "code",
        "outputId": "58d611ce-9280-42fd-fe28-8ccf2c677674",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "n_epochs = 30\n",
        "batch_size = 64\n",
        "n_batches = len(y_train)//batch_size\n",
        "correct = 0\n",
        "total = 0\n",
        "for epoch in range(n_epochs):\n",
        "    running_loss = 0\n",
        "    print_every = n_batches // 10\n",
        "    #start_time = time.time()\n",
        "    total_train_loss = 0\n",
        "    train_total = 0\n",
        "    train_correct = 0\n",
        "    for i,data in enumerate(train_loader, 0):\n",
        "        # extract data in this batch\n",
        "        inputs, labels = data\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        #Set the parameter gradients to zero\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        #Forward pass, backward pass, optimize\n",
        "      \n",
        "              \n",
        "        outputs = model(inputs.float())\n",
        "        loss_train = criterion(outputs.cuda(), labels.long().cuda())\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #Print statistics\n",
        "        running_loss += loss_train\n",
        "        total_train_loss += loss_train\n",
        "        \n",
        "\n",
        "        _, train_predicted = torch.max(outputs.data, 1)  # Choose the best class from the output: The class with the best score\n",
        "        train_total += labels.size(0)                    # Increment the total count\n",
        "        train_correct += (train_predicted == labels).sum()     # Increment the correct count\n",
        "\n",
        "        #Print every 10th batch of an epoch\n",
        "       # if (i + 1) % (print_every + 1) == 0:\n",
        "           # print(\"Epoch {}, {:d}% \\t train_loss: {:.2f} \".format(\n",
        "                    #epoch+1, int(100 * (i+1) / n_batches), running_loss / print_every))\n",
        "            #Reset running loss and time\n",
        "            #running_loss = 0.0\n",
        "        print(\"Training Acc = {:.2f}\".format(100 * train_correct / train_total))\n",
        "\n",
        "    #At the end of the epoch, do a pass on the validation set\n",
        "\n",
        "    X_val = X_val.to(device)\n",
        "    y_val = y_val.to(device)\n",
        "    output_val = model(X_val.cuda().float())\n",
        "    loss_val = criterion(output_val, y_val.long().cuda())\n",
        "\n",
        "    _, predicted = torch.max(output_val.data, 1)  # Choose the best class from the output: The class with the best score\n",
        "    total += y_val.size(0)                    # Increment the total count\n",
        "    correct += (predicted == y_val).sum()     # Increment the correct count\n",
        "    print(\"Validation Acc = {:.2f}\".format(100 * correct / total))\n",
        "    print(\"Validation loss = {:.2f}\".format(loss_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Acc = 23.00\n",
            "Training Acc = 21.00\n",
            "Training Acc = 22.00\n",
            "Training Acc = 22.00\n",
            "Training Acc = 23.00\n",
            "Training Acc = 24.00\n",
            "Training Acc = 24.00\n",
            "Training Acc = 24.00\n",
            "Training Acc = 24.00\n",
            "Training Acc = 25.00\n",
            "Training Acc = 25.00\n",
            "Training Acc = 25.00\n",
            "Training Acc = 25.00\n",
            "Training Acc = 25.00\n",
            "Training Acc = 25.00\n",
            "Training Acc = 26.00\n",
            "Training Acc = 25.00\n",
            "Training Acc = 25.00\n",
            "Training Acc = 25.00\n",
            "Validation Acc = 26.00\n",
            "Validation loss = 1.39\n",
            "Training Acc = 27.00\n",
            "Training Acc = 30.00\n",
            "Training Acc = 28.00\n",
            "Training Acc = 29.00\n",
            "Training Acc = 28.00\n",
            "Training Acc = 28.00\n",
            "Training Acc = 28.00\n",
            "Training Acc = 30.00\n",
            "Training Acc = 30.00\n",
            "Training Acc = 30.00\n",
            "Training Acc = 30.00\n",
            "Training Acc = 30.00\n",
            "Training Acc = 30.00\n",
            "Training Acc = 30.00\n",
            "Training Acc = 30.00\n",
            "Training Acc = 30.00\n",
            "Training Acc = 30.00\n",
            "Training Acc = 30.00\n",
            "Training Acc = 30.00\n",
            "Validation Acc = 28.00\n",
            "Validation loss = 1.38\n",
            "Training Acc = 28.00\n",
            "Training Acc = 30.00\n",
            "Training Acc = 29.00\n",
            "Training Acc = 30.00\n",
            "Training Acc = 31.00\n",
            "Training Acc = 31.00\n",
            "Training Acc = 33.00\n",
            "Training Acc = 32.00\n",
            "Training Acc = 32.00\n",
            "Training Acc = 32.00\n",
            "Training Acc = 32.00\n",
            "Training Acc = 32.00\n",
            "Training Acc = 32.00\n",
            "Training Acc = 32.00\n",
            "Training Acc = 32.00\n",
            "Training Acc = 32.00\n",
            "Training Acc = 31.00\n",
            "Training Acc = 32.00\n",
            "Training Acc = 32.00\n",
            "Validation Acc = 29.00\n",
            "Validation loss = 1.41\n",
            "Training Acc = 37.00\n",
            "Training Acc = 34.00\n",
            "Training Acc = 32.00\n",
            "Training Acc = 35.00\n",
            "Training Acc = 34.00\n",
            "Training Acc = 34.00\n",
            "Training Acc = 34.00\n",
            "Training Acc = 35.00\n",
            "Training Acc = 34.00\n",
            "Training Acc = 34.00\n",
            "Training Acc = 34.00\n",
            "Training Acc = 34.00\n",
            "Training Acc = 34.00\n",
            "Training Acc = 33.00\n",
            "Training Acc = 33.00\n",
            "Training Acc = 33.00\n",
            "Training Acc = 33.00\n",
            "Training Acc = 32.00\n",
            "Training Acc = 32.00\n",
            "Validation Acc = 29.00\n",
            "Validation loss = 1.38\n",
            "Training Acc = 35.00\n",
            "Training Acc = 36.00\n",
            "Training Acc = 36.00\n",
            "Training Acc = 36.00\n",
            "Training Acc = 37.00\n",
            "Training Acc = 37.00\n",
            "Training Acc = 36.00\n",
            "Training Acc = 36.00\n",
            "Training Acc = 37.00\n",
            "Training Acc = 38.00\n",
            "Training Acc = 37.00\n",
            "Training Acc = 37.00\n",
            "Training Acc = 37.00\n",
            "Training Acc = 37.00\n",
            "Training Acc = 37.00\n",
            "Training Acc = 37.00\n",
            "Training Acc = 37.00\n",
            "Training Acc = 37.00\n",
            "Training Acc = 36.00\n",
            "Validation Acc = 29.00\n",
            "Validation loss = 1.41\n",
            "Training Acc = 38.00\n",
            "Training Acc = 39.00\n",
            "Training Acc = 37.00\n",
            "Training Acc = 36.00\n",
            "Training Acc = 36.00\n",
            "Training Acc = 36.00\n",
            "Training Acc = 36.00\n",
            "Training Acc = 36.00\n",
            "Training Acc = 36.00\n",
            "Training Acc = 36.00\n",
            "Training Acc = 36.00\n",
            "Training Acc = 36.00\n",
            "Training Acc = 36.00\n",
            "Training Acc = 36.00\n",
            "Training Acc = 36.00\n",
            "Training Acc = 36.00\n",
            "Training Acc = 36.00\n",
            "Training Acc = 36.00\n",
            "Training Acc = 37.00\n",
            "Validation Acc = 30.00\n",
            "Validation loss = 1.35\n",
            "Training Acc = 37.00\n",
            "Training Acc = 40.00\n",
            "Training Acc = 38.00\n",
            "Training Acc = 37.00\n",
            "Training Acc = 38.00\n",
            "Training Acc = 38.00\n",
            "Training Acc = 37.00\n",
            "Training Acc = 37.00\n",
            "Training Acc = 37.00\n",
            "Training Acc = 37.00\n",
            "Training Acc = 37.00\n",
            "Training Acc = 38.00\n",
            "Training Acc = 38.00\n",
            "Training Acc = 38.00\n",
            "Training Acc = 38.00\n",
            "Training Acc = 38.00\n",
            "Training Acc = 39.00\n",
            "Training Acc = 38.00\n",
            "Training Acc = 39.00\n",
            "Validation Acc = 30.00\n",
            "Validation loss = 1.35\n",
            "Training Acc = 41.00\n",
            "Training Acc = 41.00\n",
            "Training Acc = 44.00\n",
            "Training Acc = 41.00\n",
            "Training Acc = 41.00\n",
            "Training Acc = 42.00\n",
            "Training Acc = 43.00\n",
            "Training Acc = 44.00\n",
            "Training Acc = 43.00\n",
            "Training Acc = 42.00\n",
            "Training Acc = 42.00\n",
            "Training Acc = 42.00\n",
            "Training Acc = 42.00\n",
            "Training Acc = 42.00\n",
            "Training Acc = 42.00\n",
            "Training Acc = 42.00\n",
            "Training Acc = 42.00\n",
            "Training Acc = 42.00\n",
            "Training Acc = 41.00\n",
            "Validation Acc = 31.00\n",
            "Validation loss = 1.42\n",
            "Training Acc = 42.00\n",
            "Training Acc = 42.00\n",
            "Training Acc = 42.00\n",
            "Training Acc = 40.00\n",
            "Training Acc = 41.00\n",
            "Training Acc = 40.00\n",
            "Training Acc = 40.00\n",
            "Training Acc = 41.00\n",
            "Training Acc = 42.00\n",
            "Training Acc = 42.00\n",
            "Training Acc = 42.00\n",
            "Training Acc = 42.00\n",
            "Training Acc = 42.00\n",
            "Training Acc = 41.00\n",
            "Training Acc = 41.00\n",
            "Training Acc = 41.00\n",
            "Training Acc = 41.00\n",
            "Training Acc = 41.00\n",
            "Training Acc = 41.00\n",
            "Validation Acc = 31.00\n",
            "Validation loss = 1.43\n",
            "Training Acc = 42.00\n",
            "Training Acc = 43.00\n",
            "Training Acc = 44.00\n",
            "Training Acc = 44.00\n",
            "Training Acc = 45.00\n",
            "Training Acc = 46.00\n",
            "Training Acc = 44.00\n",
            "Training Acc = 44.00\n",
            "Training Acc = 44.00\n",
            "Training Acc = 44.00\n",
            "Training Acc = 44.00\n",
            "Training Acc = 44.00\n",
            "Training Acc = 43.00\n",
            "Training Acc = 44.00\n",
            "Training Acc = 44.00\n",
            "Training Acc = 44.00\n",
            "Training Acc = 44.00\n",
            "Training Acc = 44.00\n",
            "Training Acc = 43.00\n",
            "Validation Acc = 32.00\n",
            "Validation loss = 1.38\n",
            "Training Acc = 46.00\n",
            "Training Acc = 48.00\n",
            "Training Acc = 47.00\n",
            "Training Acc = 47.00\n",
            "Training Acc = 47.00\n",
            "Training Acc = 47.00\n",
            "Training Acc = 46.00\n",
            "Training Acc = 46.00\n",
            "Training Acc = 46.00\n",
            "Training Acc = 46.00\n",
            "Training Acc = 45.00\n",
            "Training Acc = 45.00\n",
            "Training Acc = 44.00\n",
            "Training Acc = 44.00\n",
            "Training Acc = 44.00\n",
            "Training Acc = 45.00\n",
            "Training Acc = 45.00\n",
            "Training Acc = 44.00\n",
            "Training Acc = 44.00\n",
            "Validation Acc = 32.00\n",
            "Validation loss = 1.40\n",
            "Training Acc = 45.00\n",
            "Training Acc = 45.00\n",
            "Training Acc = 48.00\n",
            "Training Acc = 46.00\n",
            "Training Acc = 46.00\n",
            "Training Acc = 47.00\n",
            "Training Acc = 47.00\n",
            "Training Acc = 47.00\n",
            "Training Acc = 48.00\n",
            "Training Acc = 47.00\n",
            "Training Acc = 47.00\n",
            "Training Acc = 47.00\n",
            "Training Acc = 47.00\n",
            "Training Acc = 47.00\n",
            "Training Acc = 47.00\n",
            "Training Acc = 47.00\n",
            "Training Acc = 47.00\n",
            "Training Acc = 47.00\n",
            "Training Acc = 46.00\n",
            "Validation Acc = 32.00\n",
            "Validation loss = 1.33\n",
            "Training Acc = 54.00\n",
            "Training Acc = 52.00\n",
            "Training Acc = 50.00\n",
            "Training Acc = 51.00\n",
            "Training Acc = 51.00\n",
            "Training Acc = 50.00\n",
            "Training Acc = 49.00\n",
            "Training Acc = 48.00\n",
            "Training Acc = 47.00\n",
            "Training Acc = 48.00\n",
            "Training Acc = 48.00\n",
            "Training Acc = 48.00\n",
            "Training Acc = 49.00\n",
            "Training Acc = 48.00\n",
            "Training Acc = 48.00\n",
            "Training Acc = 48.00\n",
            "Training Acc = 48.00\n",
            "Training Acc = 48.00\n",
            "Training Acc = 48.00\n",
            "Validation Acc = 32.00\n",
            "Validation loss = 1.38\n",
            "Training Acc = 60.00\n",
            "Training Acc = 53.00\n",
            "Training Acc = 53.00\n",
            "Training Acc = 51.00\n",
            "Training Acc = 51.00\n",
            "Training Acc = 51.00\n",
            "Training Acc = 52.00\n",
            "Training Acc = 51.00\n",
            "Training Acc = 51.00\n",
            "Training Acc = 51.00\n",
            "Training Acc = 51.00\n",
            "Training Acc = 50.00\n",
            "Training Acc = 50.00\n",
            "Training Acc = 50.00\n",
            "Training Acc = 50.00\n",
            "Training Acc = 51.00\n",
            "Training Acc = 51.00\n",
            "Training Acc = 51.00\n",
            "Training Acc = 51.00\n",
            "Validation Acc = 33.00\n",
            "Validation loss = 1.40\n",
            "Training Acc = 56.00\n",
            "Training Acc = 56.00\n",
            "Training Acc = 52.00\n",
            "Training Acc = 52.00\n",
            "Training Acc = 51.00\n",
            "Training Acc = 51.00\n",
            "Training Acc = 51.00\n",
            "Training Acc = 51.00\n",
            "Training Acc = 51.00\n",
            "Training Acc = 50.00\n",
            "Training Acc = 50.00\n",
            "Training Acc = 50.00\n",
            "Training Acc = 51.00\n",
            "Training Acc = 52.00\n",
            "Training Acc = 52.00\n",
            "Training Acc = 52.00\n",
            "Training Acc = 52.00\n",
            "Training Acc = 52.00\n",
            "Training Acc = 52.00\n",
            "Validation Acc = 33.00\n",
            "Validation loss = 1.38\n",
            "Training Acc = 60.00\n",
            "Training Acc = 56.00\n",
            "Training Acc = 57.00\n",
            "Training Acc = 57.00\n",
            "Training Acc = 55.00\n",
            "Training Acc = 57.00\n",
            "Training Acc = 57.00\n",
            "Training Acc = 55.00\n",
            "Training Acc = 56.00\n",
            "Training Acc = 55.00\n",
            "Training Acc = 55.00\n",
            "Training Acc = 54.00\n",
            "Training Acc = 55.00\n",
            "Training Acc = 55.00\n",
            "Training Acc = 55.00\n",
            "Training Acc = 54.00\n",
            "Training Acc = 55.00\n",
            "Training Acc = 54.00\n",
            "Training Acc = 54.00\n",
            "Validation Acc = 33.00\n",
            "Validation loss = 1.41\n",
            "Training Acc = 60.00\n",
            "Training Acc = 60.00\n",
            "Training Acc = 57.00\n",
            "Training Acc = 59.00\n",
            "Training Acc = 59.00\n",
            "Training Acc = 59.00\n",
            "Training Acc = 57.00\n",
            "Training Acc = 57.00\n",
            "Training Acc = 57.00\n",
            "Training Acc = 56.00\n",
            "Training Acc = 56.00\n",
            "Training Acc = 56.00\n",
            "Training Acc = 56.00\n",
            "Training Acc = 56.00\n",
            "Training Acc = 55.00\n",
            "Training Acc = 55.00\n",
            "Training Acc = 55.00\n",
            "Training Acc = 54.00\n",
            "Training Acc = 54.00\n",
            "Validation Acc = 34.00\n",
            "Validation loss = 1.46\n",
            "Training Acc = 57.00\n",
            "Training Acc = 54.00\n",
            "Training Acc = 56.00\n",
            "Training Acc = 56.00\n",
            "Training Acc = 57.00\n",
            "Training Acc = 57.00\n",
            "Training Acc = 56.00\n",
            "Training Acc = 56.00\n",
            "Training Acc = 56.00\n",
            "Training Acc = 55.00\n",
            "Training Acc = 56.00\n",
            "Training Acc = 56.00\n",
            "Training Acc = 57.00\n",
            "Training Acc = 57.00\n",
            "Training Acc = 57.00\n",
            "Training Acc = 56.00\n",
            "Training Acc = 56.00\n",
            "Training Acc = 57.00\n",
            "Training Acc = 57.00\n",
            "Validation Acc = 34.00\n",
            "Validation loss = 1.39\n",
            "Training Acc = 54.00\n",
            "Training Acc = 60.00\n",
            "Training Acc = 62.00\n",
            "Training Acc = 61.00\n",
            "Training Acc = 63.00\n",
            "Training Acc = 62.00\n",
            "Training Acc = 62.00\n",
            "Training Acc = 62.00\n",
            "Training Acc = 61.00\n",
            "Training Acc = 61.00\n",
            "Training Acc = 60.00\n",
            "Training Acc = 59.00\n",
            "Training Acc = 60.00\n",
            "Training Acc = 60.00\n",
            "Training Acc = 61.00\n",
            "Training Acc = 60.00\n",
            "Training Acc = 60.00\n",
            "Training Acc = 60.00\n",
            "Training Acc = 60.00\n",
            "Validation Acc = 34.00\n",
            "Validation loss = 1.39\n",
            "Training Acc = 64.00\n",
            "Training Acc = 62.00\n",
            "Training Acc = 61.00\n",
            "Training Acc = 59.00\n",
            "Training Acc = 58.00\n",
            "Training Acc = 58.00\n",
            "Training Acc = 58.00\n",
            "Training Acc = 58.00\n",
            "Training Acc = 57.00\n",
            "Training Acc = 58.00\n",
            "Training Acc = 58.00\n",
            "Training Acc = 59.00\n",
            "Training Acc = 58.00\n",
            "Training Acc = 58.00\n",
            "Training Acc = 59.00\n",
            "Training Acc = 59.00\n",
            "Training Acc = 59.00\n",
            "Training Acc = 59.00\n",
            "Training Acc = 59.00\n",
            "Validation Acc = 35.00\n",
            "Validation loss = 1.27\n",
            "Training Acc = 60.00\n",
            "Training Acc = 63.00\n",
            "Training Acc = 62.00\n",
            "Training Acc = 60.00\n",
            "Training Acc = 57.00\n",
            "Training Acc = 58.00\n",
            "Training Acc = 59.00\n",
            "Training Acc = 59.00\n",
            "Training Acc = 60.00\n",
            "Training Acc = 60.00\n",
            "Training Acc = 61.00\n",
            "Training Acc = 60.00\n",
            "Training Acc = 61.00\n",
            "Training Acc = 61.00\n",
            "Training Acc = 61.00\n",
            "Training Acc = 60.00\n",
            "Training Acc = 61.00\n",
            "Training Acc = 60.00\n",
            "Training Acc = 60.00\n",
            "Validation Acc = 35.00\n",
            "Validation loss = 1.36\n",
            "Training Acc = 66.00\n",
            "Training Acc = 63.00\n",
            "Training Acc = 64.00\n",
            "Training Acc = 65.00\n",
            "Training Acc = 64.00\n",
            "Training Acc = 63.00\n",
            "Training Acc = 64.00\n",
            "Training Acc = 65.00\n",
            "Training Acc = 65.00\n",
            "Training Acc = 65.00\n",
            "Training Acc = 65.00\n",
            "Training Acc = 65.00\n",
            "Training Acc = 65.00\n",
            "Training Acc = 65.00\n",
            "Training Acc = 65.00\n",
            "Training Acc = 65.00\n",
            "Training Acc = 65.00\n",
            "Training Acc = 65.00\n",
            "Training Acc = 64.00\n",
            "Validation Acc = 35.00\n",
            "Validation loss = 1.40\n",
            "Training Acc = 73.00\n",
            "Training Acc = 69.00\n",
            "Training Acc = 68.00\n",
            "Training Acc = 68.00\n",
            "Training Acc = 68.00\n",
            "Training Acc = 67.00\n",
            "Training Acc = 66.00\n",
            "Training Acc = 65.00\n",
            "Training Acc = 65.00\n",
            "Training Acc = 65.00\n",
            "Training Acc = 65.00\n",
            "Training Acc = 64.00\n",
            "Training Acc = 65.00\n",
            "Training Acc = 65.00\n",
            "Training Acc = 65.00\n",
            "Training Acc = 64.00\n",
            "Training Acc = 64.00\n",
            "Training Acc = 64.00\n",
            "Training Acc = 65.00\n",
            "Validation Acc = 36.00\n",
            "Validation loss = 1.29\n",
            "Training Acc = 68.00\n",
            "Training Acc = 66.00\n",
            "Training Acc = 65.00\n",
            "Training Acc = 65.00\n",
            "Training Acc = 67.00\n",
            "Training Acc = 67.00\n",
            "Training Acc = 68.00\n",
            "Training Acc = 67.00\n",
            "Training Acc = 66.00\n",
            "Training Acc = 66.00\n",
            "Training Acc = 66.00\n",
            "Training Acc = 67.00\n",
            "Training Acc = 67.00\n",
            "Training Acc = 67.00\n",
            "Training Acc = 67.00\n",
            "Training Acc = 67.00\n",
            "Training Acc = 67.00\n",
            "Training Acc = 67.00\n",
            "Training Acc = 67.00\n",
            "Validation Acc = 36.00\n",
            "Validation loss = 1.44\n",
            "Training Acc = 58.00\n",
            "Training Acc = 64.00\n",
            "Training Acc = 66.00\n",
            "Training Acc = 67.00\n",
            "Training Acc = 68.00\n",
            "Training Acc = 68.00\n",
            "Training Acc = 68.00\n",
            "Training Acc = 68.00\n",
            "Training Acc = 68.00\n",
            "Training Acc = 67.00\n",
            "Training Acc = 67.00\n",
            "Training Acc = 67.00\n",
            "Training Acc = 67.00\n",
            "Training Acc = 67.00\n",
            "Training Acc = 68.00\n",
            "Training Acc = 68.00\n",
            "Training Acc = 68.00\n",
            "Training Acc = 68.00\n",
            "Training Acc = 67.00\n",
            "Validation Acc = 36.00\n",
            "Validation loss = 1.52\n",
            "Training Acc = 72.00\n",
            "Training Acc = 71.00\n",
            "Training Acc = 71.00\n",
            "Training Acc = 70.00\n",
            "Training Acc = 70.00\n",
            "Training Acc = 70.00\n",
            "Training Acc = 68.00\n",
            "Training Acc = 68.00\n",
            "Training Acc = 68.00\n",
            "Training Acc = 68.00\n",
            "Training Acc = 68.00\n",
            "Training Acc = 69.00\n",
            "Training Acc = 68.00\n",
            "Training Acc = 68.00\n",
            "Training Acc = 68.00\n",
            "Training Acc = 69.00\n",
            "Training Acc = 68.00\n",
            "Training Acc = 68.00\n",
            "Training Acc = 68.00\n",
            "Validation Acc = 36.00\n",
            "Validation loss = 1.51\n",
            "Training Acc = 79.00\n",
            "Training Acc = 78.00\n",
            "Training Acc = 77.00\n",
            "Training Acc = 75.00\n",
            "Training Acc = 74.00\n",
            "Training Acc = 73.00\n",
            "Training Acc = 73.00\n",
            "Training Acc = 73.00\n",
            "Training Acc = 71.00\n",
            "Training Acc = 71.00\n",
            "Training Acc = 71.00\n",
            "Training Acc = 71.00\n",
            "Training Acc = 71.00\n",
            "Training Acc = 71.00\n",
            "Training Acc = 71.00\n",
            "Training Acc = 70.00\n",
            "Training Acc = 71.00\n",
            "Training Acc = 71.00\n",
            "Training Acc = 71.00\n",
            "Validation Acc = 37.00\n",
            "Validation loss = 1.52\n",
            "Training Acc = 80.00\n",
            "Training Acc = 76.00\n",
            "Training Acc = 74.00\n",
            "Training Acc = 75.00\n",
            "Training Acc = 73.00\n",
            "Training Acc = 74.00\n",
            "Training Acc = 74.00\n",
            "Training Acc = 74.00\n",
            "Training Acc = 74.00\n",
            "Training Acc = 74.00\n",
            "Training Acc = 74.00\n",
            "Training Acc = 75.00\n",
            "Training Acc = 75.00\n",
            "Training Acc = 75.00\n",
            "Training Acc = 74.00\n",
            "Training Acc = 74.00\n",
            "Training Acc = 75.00\n",
            "Training Acc = 75.00\n",
            "Training Acc = 75.00\n",
            "Validation Acc = 37.00\n",
            "Validation loss = 1.60\n",
            "Training Acc = 81.00\n",
            "Training Acc = 80.00\n",
            "Training Acc = 77.00\n",
            "Training Acc = 77.00\n",
            "Training Acc = 77.00\n",
            "Training Acc = 76.00\n",
            "Training Acc = 74.00\n",
            "Training Acc = 75.00\n",
            "Training Acc = 75.00\n",
            "Training Acc = 76.00\n",
            "Training Acc = 75.00\n",
            "Training Acc = 76.00\n",
            "Training Acc = 76.00\n",
            "Training Acc = 76.00\n",
            "Training Acc = 75.00\n",
            "Training Acc = 75.00\n",
            "Training Acc = 75.00\n",
            "Training Acc = 75.00\n",
            "Training Acc = 75.00\n",
            "Validation Acc = 37.00\n",
            "Validation loss = 1.55\n",
            "Training Acc = 79.00\n",
            "Training Acc = 80.00\n",
            "Training Acc = 80.00\n",
            "Training Acc = 79.00\n",
            "Training Acc = 78.00\n",
            "Training Acc = 79.00\n",
            "Training Acc = 79.00\n",
            "Training Acc = 79.00\n",
            "Training Acc = 78.00\n",
            "Training Acc = 77.00\n",
            "Training Acc = 76.00\n",
            "Training Acc = 77.00\n",
            "Training Acc = 77.00\n",
            "Training Acc = 77.00\n",
            "Training Acc = 77.00\n",
            "Training Acc = 77.00\n",
            "Training Acc = 77.00\n",
            "Training Acc = 77.00\n",
            "Training Acc = 76.00\n",
            "Validation Acc = 37.00\n",
            "Validation loss = 1.66\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
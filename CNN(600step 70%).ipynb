{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ayz7OdLDIi_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn \n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset, TensorDataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da4KnZ7uIrHS",
        "colab_type": "code",
        "outputId": "0682e1a1-c46e-4b0a-90e8-5acff08d30a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive/ECE 247/project/project"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/ECE 247/project/project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2csF5WBYKrum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "X_test = np.load(\"X_test.npy\")\n",
        "y_test = np.load(\"y_test.npy\")\n",
        "person_train_valid = np.load(\"person_train_valid.npy\")\n",
        "X_train_valid = np.load(\"X_train_valid.npy\")\n",
        "y_train_valid = np.load(\"y_train_valid.npy\")\n",
        "person_test = np.load(\"person_test.npy\")\n",
        "y_train_valid = y_train_valid - 769\n",
        "y_test = y_test - 769\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxoBAaCrKxni",
        "colab_type": "code",
        "outputId": "8092738a-258e-4722-a814-d9f2610da0ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
        "print ('Test data shape: {}'.format(X_test.shape))\n",
        "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
        "print ('Test target shape: {}'.format(y_test.shape))\n",
        "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
        "print ('Person test shape: {}'.format(person_test.shape))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training/Valid data shape: (2115, 22, 1000)\n",
            "Test data shape: (443, 22, 1000)\n",
            "Training/Valid target shape: (2115,)\n",
            "Test target shape: (443,)\n",
            "Person train/valid shape: (2115, 1)\n",
            "Person test shape: (443, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJA6PwPNXxPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def datatime(X,X_test,sub_idx=None, time_period=1000):\n",
        "    # different period of time\n",
        "    X_train_valid_time = X[:, :, :time_period]\n",
        "    X_test_time = X_test[:, :, :time_period]\n",
        "    return X_train_valid_time,X_test_time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIgGRJHxNz4G",
        "colab_type": "code",
        "outputId": "acb10bd1-8e77-4162-d311-30193cb9be12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device('cuda:0' if use_cuda else 'cpu')\n",
        "print(device)\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla P100-PCIE-16GB'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVFZ5H5_Kz82",
        "colab_type": "code",
        "outputId": "00e1baf0-8b13-4c4c-c479-2d1790b77563",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "dtype = torch.cuda.FloatTensor\n",
        "\n",
        "\n",
        "X_train_valid_cur, X_test_cur= datatime(X_train_valid, X_test,time_period=600)\n",
        "\n",
        "perm = np.random.permutation(X_train_valid_cur.shape[0])\n",
        "numTrain = int(0.9*X_train_valid_cur.shape[0])\n",
        "numVal = X_train_valid_cur.shape[0] - numTrain\n",
        "Xtrain = X_train_valid_cur[perm[0:numTrain]]\n",
        "ytrain = y_train_valid[perm[0:numTrain]]\n",
        "Xval = X_train_valid_cur[perm[numTrain:]]\n",
        "yval = y_train_valid[perm[numTrain:]]\n",
        "\n",
        "\n",
        "X_train_reshape = np.expand_dims(Xtrain, axis=1)\n",
        "X_val_reshape = np.expand_dims(Xval, axis=1)\n",
        "print(X_train_reshape.shape)\n",
        "\n",
        "\n",
        "x_train_tensor = torch.from_numpy(X_train_reshape).float()\n",
        "y_train_tensor = torch.from_numpy(ytrain).float()\n",
        "\n",
        "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "\n",
        "x_val_tensor = torch.from_numpy(X_val_reshape).float()\n",
        "y_val_tensor = torch.from_numpy(yval).float()\n",
        "\n",
        "val_data = TensorDataset(x_val_tensor, y_val_tensor)\n",
        "\n",
        "print(train_data[0])\n",
        "batchsize = 32\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=batchsize, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_data, batch_size=batchsize, shuffle=True)\n",
        "\n",
        "N,C,H,W = X_train_reshape.shape\n",
        "x = Variable(torch.randn(N,C,H,W))\n",
        "y= Variable(torch.Tensor(ytrain), requires_grad = False)\n",
        "x.type(dtype)\n",
        "y.type(dtype)\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1903, 1, 22, 600)\n",
            "(tensor([[[ 7.4707,  5.0293, 10.7910,  ..., 15.7227,  7.5195, 14.6484],\n",
            "         [ 5.8594,  7.5195, 12.3047,  ..., 16.4062, 10.7422, 18.1641],\n",
            "         [ 7.7637,  4.9316, 11.7188,  ..., 18.3594,  9.0332, 16.4062],\n",
            "         ...,\n",
            "         [12.2559,  8.7402, 13.7695,  ..., 11.8652,  5.7129, 11.7188],\n",
            "         [12.4512,  8.6914, 15.1855,  ..., 10.6445,  5.3223, 10.6934],\n",
            "         [11.2305,  6.3965, 12.3535,  ..., 12.8418,  4.8340,  9.6680]]]), tensor(1.))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 0.,  ..., 0., 2., 1.], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dWIWO5qXkPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InceptionNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(InceptionNet, self).__init__()\n",
        "        self.conv0 = nn.Conv2d(in_channels=22, out_channels=32, kernel_size=(1,9), stride=(1,1), padding=(0,4))\n",
        "        self.conv0_bn = nn.BatchNorm2d(32)\n",
        "        self.conv1 = nn.Conv2d(in_channels=22, out_channels=32, kernel_size=(1,7), stride=(1,1), padding=(0,3))\n",
        "        self.conv1_bn = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(in_channels=22, out_channels=32, kernel_size=(1,5), stride=(1,1), padding=(0,2))\n",
        "        self.conv2_bn = nn.BatchNorm2d(32)\n",
        "        self.conv3 = nn.Conv2d(in_channels=22, out_channels=32, kernel_size=(1,3), stride=(1,1), padding=(0,1))\n",
        "        self.conv3_bn = nn.BatchNorm2d(32)\n",
        "        self.conv4 = nn.Conv2d(in_channels=22, out_channels=32, kernel_size=(1,1), stride=(1,1))\n",
        "        self.conv4_bn = nn.BatchNorm2d(32)\n",
        "        \n",
        "        self.conv5 = nn.Conv2d(in_channels=160, out_channels=64, kernel_size=(1,9), stride=(1,1), padding=(0,4))\n",
        "        self.conv5_bn = nn.BatchNorm2d(64)       \n",
        "        self.conv6 = nn.Conv2d(in_channels=160, out_channels=64, kernel_size=(1,7), stride=(1,1), padding=(0,3))\n",
        "        self.conv6_bn = nn.BatchNorm2d(64)\n",
        "        self.conv7 = nn.Conv2d(in_channels=160, out_channels=64, kernel_size=(1,5), stride=(1,1), padding=(0,2))\n",
        "        self.conv7_bn = nn.BatchNorm2d(64)\n",
        "        self.conv8 = nn.Conv2d(in_channels=160, out_channels=64, kernel_size=(1,3), stride=(1,1), padding=(0,1))\n",
        "        self.conv8_bn = nn.BatchNorm2d(64)        \n",
        "        self.conv9 = nn.Conv2d(in_channels=160, out_channels=64, kernel_size=(1,1), stride=(1,1), padding=(0,0))\n",
        "        self.conv9_bn = nn.BatchNorm2d(64)\n",
        "        \n",
        "        self.conv10 = nn.Conv2d(in_channels=320, out_channels=128, kernel_size=(1,9), stride=(1,1), padding=(0,4))\n",
        "        self.conv10_bn = nn.BatchNorm2d(128)       \n",
        "        self.conv11 = nn.Conv2d(in_channels=320, out_channels=128, kernel_size=(1,7), stride=(1,1), padding=(0,3))\n",
        "        self.conv11_bn = nn.BatchNorm2d(128)\n",
        "        self.conv12 = nn.Conv2d(in_channels=320, out_channels=128, kernel_size=(1,5), stride=(1,1), padding=(0,2))\n",
        "        self.conv12_bn = nn.BatchNorm2d(128)\n",
        "        self.conv13 = nn.Conv2d(in_channels=320, out_channels=128, kernel_size=(1,3), stride=(1,1), padding=(0,1))\n",
        "        self.conv13_bn = nn.BatchNorm2d(128)        \n",
        "        self.conv14 = nn.Conv2d(in_channels=320, out_channels=128, kernel_size=(1,1), stride=(1,1), padding=(0,0))\n",
        "        self.conv14_bn = nn.BatchNorm2d(128)\n",
        "        \n",
        "        self.relu = nn.ELU(inplace=True) #nn.ReLU(inplace=True)\n",
        "        \n",
        "        self.fc = nn.Linear(in_features=640*15,  out_features=4)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=(1,2), stride=(1,2), padding=(0,0))\n",
        "        self.avgpool = nn.AvgPool2d(kernel_size=(1,10), stride=(1,10), padding=(0,0))\n",
        "        \n",
        "        \n",
        "        \n",
        "    def forward(self, X):\n",
        "        # Nx1x22x1000\n",
        "        xi = X.permute(0,2,1,3)\n",
        "        x = self.conv0(xi)\n",
        "        x = self.conv0_bn(x)\n",
        "        x0 = self.relu(x)\n",
        "        x = self.conv1(xi)\n",
        "        x = self.conv1_bn(x)\n",
        "        x1 = self.relu(x)\n",
        "        x = self.conv2(xi)\n",
        "        x = self.conv2_bn(x)\n",
        "        x2 = self.relu(x)\n",
        "        x = self.conv3(xi)\n",
        "        x = self.conv3_bn(x)\n",
        "        x3 = self.relu(x)\n",
        "        x = self.conv4(xi)\n",
        "        x = self.conv4_bn(x)\n",
        "        x4 = self.relu(x)\n",
        "        x = torch.cat((x0,x1,x2,x3,x4),1)\n",
        "        \n",
        "        xi = self.maxpool(x)\n",
        "                \n",
        "        x = self.conv5(xi)\n",
        "        x = self.conv5_bn(x)\n",
        "        x0 = self.relu(x)\n",
        "        x = self.conv6(xi)\n",
        "        x = self.conv6_bn(x)\n",
        "        x1 = self.relu(x)\n",
        "        x = self.conv7(xi)\n",
        "        x = self.conv7_bn(x)\n",
        "        x2 = self.relu(x)\n",
        "        x = self.conv8(xi)\n",
        "        x = self.conv8_bn(x)\n",
        "        x3 = self.relu(x)\n",
        "        x = self.conv9(xi)\n",
        "        x = self.conv9_bn(x)\n",
        "        x4 = self.relu(x)\n",
        "        x = torch.cat((x0,x1,x2,x3,x4),1)\n",
        "       \n",
        "        xi = self.maxpool(x)\n",
        "\n",
        "        x = self.conv10(xi)\n",
        "        x = self.conv10_bn(x)\n",
        "        x0 = self.relu(x)\n",
        "        x = self.conv11(xi)\n",
        "        x = self.conv11_bn(x)\n",
        "        x1 = self.relu(x)\n",
        "        x = self.conv12(xi)\n",
        "        x = self.conv12_bn(x)\n",
        "        x2 = self.relu(x)\n",
        "        x = self.conv13(xi)\n",
        "        x = self.conv13_bn(x)\n",
        "        x3 = self.relu(x)\n",
        "        x = self.conv14(xi)\n",
        "        x = self.conv14_bn(x)\n",
        "        x4 = self.relu(x)\n",
        "        x = torch.cat((x0,x1,x2,x3,x4),1)\n",
        "        #print(x.shape)\n",
        "        x = self.avgpool(x)\n",
        "        #print(x.shape)\n",
        "        x = x.reshape((-1, 640*15))\n",
        "        #print(x.shape)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "model = InceptionNet()\n",
        "model = model.float()\n",
        "model.type(dtype)\n",
        "model= model.to(device)   \n",
        "loss_fn = nn.CrossEntropyLoss().type(dtype)\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRJRo71lK9yb",
        "colab_type": "code",
        "outputId": "97aed07a-c272-419b-8cb1-78638b8fe871",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for t in range(42):\n",
        "  for x_batch, y_batch in train_loader:\n",
        "\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "        model.zero_grad()\n",
        "\n",
        "        y_pred = model(x_batch)\n",
        "\n",
        "        loss = loss_fn(y_pred, y_batch.type(torch.LongTensor).cuda())\n",
        "    \n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(y_pred.data, 1)  # Choose the best class from the output: The class with the best score\n",
        "        total += y_batch.size(0)                    # Increment the total count\n",
        "        correct += (predicted == y_batch).sum()     # Increment the correct count\n",
        "    \n",
        "  print('Accuracy of the network on the training set: %d %%' % (100 * correct / total))\n",
        "\n",
        "  #print(loss)\n",
        "        "
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the training set: 42 %\n",
            "Accuracy of the network on the training set: 46 %\n",
            "Accuracy of the network on the training set: 51 %\n",
            "Accuracy of the network on the training set: 54 %\n",
            "Accuracy of the network on the training set: 58 %\n",
            "Accuracy of the network on the training set: 60 %\n",
            "Accuracy of the network on the training set: 62 %\n",
            "Accuracy of the network on the training set: 65 %\n",
            "Accuracy of the network on the training set: 66 %\n",
            "Accuracy of the network on the training set: 68 %\n",
            "Accuracy of the network on the training set: 70 %\n",
            "Accuracy of the network on the training set: 71 %\n",
            "Accuracy of the network on the training set: 73 %\n",
            "Accuracy of the network on the training set: 74 %\n",
            "Accuracy of the network on the training set: 75 %\n",
            "Accuracy of the network on the training set: 76 %\n",
            "Accuracy of the network on the training set: 77 %\n",
            "Accuracy of the network on the training set: 78 %\n",
            "Accuracy of the network on the training set: 79 %\n",
            "Accuracy of the network on the training set: 80 %\n",
            "Accuracy of the network on the training set: 81 %\n",
            "Accuracy of the network on the training set: 81 %\n",
            "Accuracy of the network on the training set: 82 %\n",
            "Accuracy of the network on the training set: 83 %\n",
            "Accuracy of the network on the training set: 83 %\n",
            "Accuracy of the network on the training set: 84 %\n",
            "Accuracy of the network on the training set: 84 %\n",
            "Accuracy of the network on the training set: 85 %\n",
            "Accuracy of the network on the training set: 85 %\n",
            "Accuracy of the network on the training set: 86 %\n",
            "Accuracy of the network on the training set: 86 %\n",
            "Accuracy of the network on the training set: 86 %\n",
            "Accuracy of the network on the training set: 87 %\n",
            "Accuracy of the network on the training set: 87 %\n",
            "Accuracy of the network on the training set: 88 %\n",
            "Accuracy of the network on the training set: 88 %\n",
            "Accuracy of the network on the training set: 88 %\n",
            "Accuracy of the network on the training set: 88 %\n",
            "Accuracy of the network on the training set: 89 %\n",
            "Accuracy of the network on the training set: 89 %\n",
            "Accuracy of the network on the training set: 89 %\n",
            "Accuracy of the network on the training set: 90 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkXMU0XSxrX-",
        "colab_type": "code",
        "outputId": "557d7c24-3b62-4ce8-fc82-9b989abb03e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for x_batch, y_batch in val_loader:\n",
        "\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "        model.zero_grad()\n",
        "\n",
        "        outputs = model(x_batch)\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)  # Choose the best class from the output: The class with the best score\n",
        "        total += y_batch.size(0)                    # Increment the total count\n",
        "        correct += (predicted == y_batch).sum()     # Increment the correct count\n",
        "    \n",
        "print('Accuracy of the network on the test set: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test set: 73 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FCC6-6k8l0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_reshape = np.expand_dims(X_test_cur, axis=1)\n",
        "x_test_tensor = torch.from_numpy(X_test_reshape).float()\n",
        "y_test_tensor = torch.from_numpy(y_test).float()\n",
        "\n",
        "test_data = TensorDataset(x_test_tensor, y_test_tensor)\n",
        "test_loader = DataLoader(dataset=test_data, batch_size=batchsize, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_nWhC0i8sVE",
        "colab_type": "code",
        "outputId": "75141f3c-f99d-461c-b179-e4ee1e5fbfd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "for x_batch, y_batch in test_loader:\n",
        "\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "        model.zero_grad()\n",
        "        outputs = model(x_batch)\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)  # Choose the best class from the output: The class with the best score\n",
        "        total += y_batch.size(0)                    # Increment the total count\n",
        "        correct += (predicted == y_batch).sum()     # Increment the correct count\n",
        "    \n",
        "print('Accuracy of the network on the test set: %d %%' % (100 * correct / total))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test set: 70 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
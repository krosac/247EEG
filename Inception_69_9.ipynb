{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"colab":{"name":"cnn_rnn.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"DiGI0306sEJX","colab_type":"code","outputId":"38d43feb-4db7-4a75-9f87-bda6d85095dd","executionInfo":{"status":"ok","timestamp":1584205952426,"user_tz":420,"elapsed":26711,"user":{"displayName":"TIANDONG ZHAO","photoUrl":"","userId":"11642193898420831601"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sKSF1YIpsmIu","colab_type":"code","colab":{}},"source":["import os\n","os.chdir(\"drive/My Drive/Colab Notebooks\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dwjCfkAvljYG","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","# for creating validation set\n","from sklearn.model_selection import train_test_split\n","# for evaluating the model\n","from sklearn.metrics import accuracy_score\n","from tqdm import tqdm\n","import random\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from torch.utils.data import TensorDataset, DataLoader\n","from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout, ELU\n","from torch.optim import Adam, SGD"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_s3z8cH-p4Do","colab_type":"code","colab":{}},"source":["# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","else:\n","    device = torch.device(\"cpu\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aZaOGTyLjgRl","colab_type":"code","outputId":"c1c4b924-d3f2-4fa4-b667-e994cd8c451f","executionInfo":{"status":"ok","timestamp":1584205983623,"user_tz":420,"elapsed":403,"user":{"displayName":"TIANDONG ZHAO","photoUrl":"","userId":"11642193898420831601"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["device"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"ZzjOal5dljYM","colab_type":"code","colab":{}},"source":["X_test = np.load(\"X_test.npy\")\n","y_test = np.load(\"y_test.npy\")\n","person_train_valid = np.load(\"person_train_valid.npy\")\n","X_train_valid = np.load(\"X_train_valid.npy\")\n","y_train_valid = np.load(\"y_train_valid.npy\")\n","person_test = np.load(\"person_test.npy\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8pNlBDcfljYP","colab_type":"code","outputId":"ea009010-eb61-48a1-ae9b-e90c5f8f7af6","executionInfo":{"status":"ok","timestamp":1584205995040,"user_tz":420,"elapsed":365,"user":{"displayName":"TIANDONG ZHAO","photoUrl":"","userId":"11642193898420831601"}},"colab":{"base_uri":"https://localhost:8080/","height":118}},"source":["print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n","print ('Test data shape: {}'.format(X_test.shape))\n","print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n","print ('Test target shape: {}'.format(y_test.shape))\n","print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n","print ('Person test shape: {}'.format(person_test.shape))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Training/Valid data shape: (2115, 22, 1000)\n","Test data shape: (443, 22, 1000)\n","Training/Valid target shape: (2115,)\n","Test target shape: (443,)\n","Person train/valid shape: (2115, 1)\n","Person test shape: (443, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f1OTW12fljYT","colab_type":"code","outputId":"7a628565-bfaf-4250-b86b-b6dfffa03e6a","executionInfo":{"status":"ok","timestamp":1584205998453,"user_tz":420,"elapsed":478,"user":{"displayName":"TIANDONG ZHAO","photoUrl":"","userId":"11642193898420831601"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# create labels \n","y_train_valid = y_train_valid - 769\n","y_test = y_test -769\n","\n","person_train_valid = person_train_valid.squeeze()\n","\n","\n","# split training and validation\n","X_train, X_val, y_train, y_val, person_train, person_val = train_test_split(X_train_valid, y_train_valid, person_train_valid, test_size = 0.1)\n","data = []\n","(X_train.shape, y_train.shape, person_train.shape), (X_val.shape, y_val.shape, person_val.shape)"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(((1903, 22, 1000), (1903,), (1903,)), ((212, 22, 1000), (212,), (212,)))"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"TgNpsbBkljYX","colab_type":"code","colab":{}},"source":["# transform to torch tensor\n","X_train = torch.from_numpy(X_train)\n","y_train = torch.from_numpy(y_train)\n","\n","X_val = torch.from_numpy(X_val)\n","y_val = torch.from_numpy(y_val)\n","\n","X_test = torch.from_numpy(X_test)\n","y_test = torch.from_numpy(y_test)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pkBYmEyQAAIg","colab":{}},"source":["class InceptionNet(nn.Module):\n","    def __init__(self):\n","        super(InceptionNet, self).__init__()\n","        self.conv0 = nn.Conv2d(in_channels=22, out_channels=32, kernel_size=(1,9), stride=(1,1), padding=(0,4))\n","        self.conv0_bn = nn.BatchNorm2d(32)\n","        self.conv1 = nn.Conv2d(in_channels=22, out_channels=32, kernel_size=(1,7), stride=(1,1), padding=(0,3))\n","        self.conv1_bn = nn.BatchNorm2d(32)\n","        self.conv2 = nn.Conv2d(in_channels=22, out_channels=32, kernel_size=(1,5), stride=(1,1), padding=(0,2))\n","        self.conv2_bn = nn.BatchNorm2d(32)\n","        self.conv3 = nn.Conv2d(in_channels=22, out_channels=32, kernel_size=(1,3), stride=(1,1), padding=(0,1))\n","        self.conv3_bn = nn.BatchNorm2d(32)\n","        self.conv4 = nn.Conv2d(in_channels=22, out_channels=32, kernel_size=(1,1), stride=(1,1))\n","        self.conv4_bn = nn.BatchNorm2d(32)\n","        \n","        self.conv5 = nn.Conv2d(in_channels=160, out_channels=64, kernel_size=(1,9), stride=(1,1), padding=(0,4))\n","        self.conv5_bn = nn.BatchNorm2d(64)       \n","        self.conv6 = nn.Conv2d(in_channels=160, out_channels=64, kernel_size=(1,7), stride=(1,1), padding=(0,3))\n","        self.conv6_bn = nn.BatchNorm2d(64)\n","        self.conv7 = nn.Conv2d(in_channels=160, out_channels=64, kernel_size=(1,5), stride=(1,1), padding=(0,2))\n","        self.conv7_bn = nn.BatchNorm2d(64)\n","        self.conv8 = nn.Conv2d(in_channels=160, out_channels=64, kernel_size=(1,3), stride=(1,1), padding=(0,1))\n","        self.conv8_bn = nn.BatchNorm2d(64)        \n","        self.conv9 = nn.Conv2d(in_channels=160, out_channels=64, kernel_size=(1,1), stride=(1,1), padding=(0,0))\n","        self.conv9_bn = nn.BatchNorm2d(64)\n","        \n","        self.conv10 = nn.Conv2d(in_channels=320, out_channels=128, kernel_size=(1,9), stride=(1,1), padding=(0,4))\n","        self.conv10_bn = nn.BatchNorm2d(128)       \n","        self.conv11 = nn.Conv2d(in_channels=320, out_channels=128, kernel_size=(1,7), stride=(1,1), padding=(0,3))\n","        self.conv11_bn = nn.BatchNorm2d(128)\n","        self.conv12 = nn.Conv2d(in_channels=320, out_channels=128, kernel_size=(1,5), stride=(1,1), padding=(0,2))\n","        self.conv12_bn = nn.BatchNorm2d(128)\n","        self.conv13 = nn.Conv2d(in_channels=320, out_channels=128, kernel_size=(1,3), stride=(1,1), padding=(0,1))\n","        self.conv13_bn = nn.BatchNorm2d(128)        \n","        self.conv14 = nn.Conv2d(in_channels=320, out_channels=128, kernel_size=(1,1), stride=(1,1), padding=(0,0))\n","        self.conv14_bn = nn.BatchNorm2d(128)\n","        \n","        self.relu = nn.ELU(inplace=True) #nn.ReLU(inplace=True)\n","        \n","        self.fc = nn.Linear(in_features=640,  out_features=4)\n","        self.maxpool = nn.MaxPool2d(kernel_size=(1,10), stride=(1,5), padding=(0,0))\n","        self.avgpool = nn.AvgPool2d(kernel_size=(1,38), stride=(1,38), padding=(0,0))\n","        \n","        \n","        \n","    def forward(self, X):\n","        # Nx1x22x1000\n","        xi = X.reshape(X.size(0),1,X.size(1),X.size(2)).permute(0,2,1,3)\n","        x = self.conv0(xi)\n","        x = self.conv0_bn(x)\n","        x0 = self.relu(x)\n","        x = self.conv1(xi)\n","        x = self.conv1_bn(x)\n","        x1 = self.relu(x)\n","        x = self.conv2(xi)\n","        x = self.conv2_bn(x)\n","        x2 = self.relu(x)\n","        x = self.conv3(xi)\n","        x = self.conv3_bn(x)\n","        x3 = self.relu(x)\n","        x = self.conv4(xi)\n","        x = self.conv4_bn(x)\n","        x4 = self.relu(x)\n","        x = torch.cat((x0,x1,x2,x3,x4),1)\n","        \n","        xi = self.maxpool(x)\n","                \n","        x = self.conv5(xi)\n","        x = self.conv5_bn(x)\n","        x0 = self.relu(x)\n","        x = self.conv6(xi)\n","        x = self.conv6_bn(x)\n","        x1 = self.relu(x)\n","        x = self.conv7(xi)\n","        x = self.conv7_bn(x)\n","        x2 = self.relu(x)\n","        x = self.conv8(xi)\n","        x = self.conv8_bn(x)\n","        x3 = self.relu(x)\n","        x = self.conv9(xi)\n","        x = self.conv9_bn(x)\n","        x4 = self.relu(x)\n","        x = torch.cat((x0,x1,x2,x3,x4),1)\n","       \n","        xi = self.maxpool(x)\n","\n","        x = self.conv10(xi)\n","        x = self.conv10_bn(x)\n","        x0 = self.relu(x)\n","        x = self.conv11(xi)\n","        x = self.conv11_bn(x)\n","        x1 = self.relu(x)\n","        x = self.conv12(xi)\n","        x = self.conv12_bn(x)\n","        x2 = self.relu(x)\n","        x = self.conv13(xi)\n","        x = self.conv13_bn(x)\n","        x3 = self.relu(x)\n","        x = self.conv14(xi)\n","        x = self.conv14_bn(x)\n","        x4 = self.relu(x)\n","        x = torch.cat((x0,x1,x2,x3,x4),1)\n","\n","        x = self.avgpool(x)\n","        x = self.fc(x.squeeze())\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Qd5wT3pMPW45","colab":{}},"source":["# reduce maxpooling layers\n","class Net(Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","\n","        self.ave = nn.AvgPool1d(kernel_size = 10, stride = 10)\n","        # 22*100\n","        self.cnn_layers = Sequential(\n","            # first conv\n","            nn.Conv1d(in_channels = 22, out_channels = 32, kernel_size = 3, stride=1),\n","            nn.BatchNorm1d(32),\n","            nn.ELU(inplace=True),\n","\n","            # second conv\n","            nn.Conv1d(in_channels = 32, out_channels = 32, kernel_size = 3, stride=1),\n","            nn.BatchNorm1d(32),\n","            nn.ELU(inplace=True),\n","\n","            # third conv\n","            nn.Conv1d(in_channels = 32, out_channels = 32, kernel_size = 3, stride=1),\n","            nn.BatchNorm1d(32),\n","            nn.ELU(inplace=True),\n","            nn.MaxPool1d(kernel_size=4, stride=2),\n","            # 64*46\n","        )\n","\n","        self.lstm= nn.LSTM(32, 16, 4, batch_first=True, dropout = 0.1, bidirectional = True)\n","\n","        self.linear_layers = Sequential(\n","            Linear(46*32,128),\n","            nn.BatchNorm1d(128),\n","            ReLU(inplace=True),\n","\n","            Linear(128,32),\n","            nn.BatchNorm1d(32),\n","            ReLU(inplace=True),\n","\n","            Linear(32, 4)\n","        )\n","        \n","    def forward(self, x):\n","        x = self.ave(x)\n","        x = self.cnn_layers(x)\n","        x = x.transpose(1, 2)\n","        x,_ = self.lstm(x)\n","        x = x.reshape((-1, 46*32))\n","        x = self.linear_layers(x)\n","        return x\n","        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"itEL-Vcz2tq6","colab":{}},"source":["# class Net(Module):\n","#     def __init__(self):\n","#         super(Net, self).__init__()\n","\n","#         self.ave = nn.AvgPool1d(kernel_size = 10, stride = 10)\n","#         # 22*50\n","#         self.fc1 = Linear(22, 10)\n","#         # 50*7\n","#         self.lstm= nn.LSTM(10, 64, 4, batch_first=True, dropout = 0)\n","\n","#         # 64\n","#         self.linear_layers = Sequential(\n","#             Linear(64*100,128),\n","#             nn.BatchNorm1d(128),\n","#             ReLU(inplace=True),\n","\n","#             Linear(128,32),\n","#             nn.BatchNorm1d(32),\n","#             ReLU(inplace=True),\n","\n","#             Linear(32, 4)\n","#         )\n","        \n","#     def forward(self, x):\n","#         x = self.ave(x)\n","#         x = x.transpose(1, 2)\n","#         x = self.fc1(x)\n","#         x,_ = self.lstm(x)\n","#         # x = x[:, -1, :]\n","#         # x = self.linear_layers(x.squeeze())\n","#         x = x.reshape((-1, 64*100))\n","#         x = self.linear_layers(x)\n","#         return x\n","        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XB3yXly1ljYd","colab_type":"code","outputId":"030c978a-0603-4613-a626-03553c37dc86","executionInfo":{"status":"ok","timestamp":1584209068604,"user_tz":420,"elapsed":353,"user":{"displayName":"TIANDONG ZHAO","photoUrl":"","userId":"11642193898420831601"}},"colab":{"base_uri":"https://localhost:8080/","height":622}},"source":["# defining the model\n","model = InceptionNet() #Net()\n","model = model.float()\n","\n","# defining the loss function\n","criterion = CrossEntropyLoss()\n","# checking if GPU is available\n","if torch.cuda.is_available():\n","    model = model.cuda()\n","    criterion = criterion.cuda()\n","\n","print(model)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["InceptionNet(\n","  (conv0): Conv2d(22, 32, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4))\n","  (conv0_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv1): Conv2d(22, 32, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n","  (conv1_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv2): Conv2d(22, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n","  (conv2_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv3): Conv2d(22, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n","  (conv3_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv4): Conv2d(22, 32, kernel_size=(1, 1), stride=(1, 1))\n","  (conv4_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv5): Conv2d(160, 64, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4))\n","  (conv5_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv6): Conv2d(160, 64, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n","  (conv6_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv7): Conv2d(160, 64, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n","  (conv7_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv8): Conv2d(160, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n","  (conv8_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv9): Conv2d(160, 64, kernel_size=(1, 1), stride=(1, 1))\n","  (conv9_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv10): Conv2d(320, 128, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4))\n","  (conv10_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv11): Conv2d(320, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3))\n","  (conv11_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv12): Conv2d(320, 128, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2))\n","  (conv12_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv13): Conv2d(320, 128, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n","  (conv13_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (conv14): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1))\n","  (conv14_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ELU(alpha=1.0, inplace=True)\n","  (fc): Linear(in_features=640, out_features=4, bias=True)\n","  (maxpool): MaxPool2d(kernel_size=(1, 10), stride=(1, 5), padding=(0, 0), dilation=1, ceil_mode=False)\n","  (avgpool): AvgPool2d(kernel_size=(1, 38), stride=(1, 38), padding=(0, 0))\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sCQumdKDFaHY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"043f56eb-a2fb-4ee4-d58a-ece4e400886b","executionInfo":{"status":"ok","timestamp":1584209080245,"user_tz":420,"elapsed":852,"user":{"displayName":"TIANDONG ZHAO","photoUrl":"","userId":"11642193898420831601"}}},"source":["model = InceptionNet()\n","model = model.float()\n","if torch.cuda.is_available():\n","    model = model.cuda()\n","    criterion = criterion.cuda()\n","model.load_state_dict(torch.load(\"Inception_69_9.pth\"))\n","## test accuracy\n","with torch.no_grad():\n","    output = model(X_test.to(device).cuda().float())\n","softmax = torch.exp(output).cpu()\n","prob = list(softmax.numpy())\n","predictions = np.argmax(prob, axis=1)\n","\n","# accuracy on test set\n","test_acc = accuracy_score(y_test.cpu(), predictions)\n","print(test_acc)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["0.6997742663656885\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"irMLoZ0inz4j","colab_type":"code","colab":{}},"source":["\n","##### hyperparameters#########\n","batch_size = 10\n","lrs = [1e-3]\n","weight_decay = 0 # regularization\n","optimizer = Adam(model.parameters(), lr=lrs[0],  weight_decay=weight_decay)\n","n_epochs = 200\n","train_losses = []\n","val_losses = []\n","train_data = TensorDataset(X_train, y_train)\n","train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last=True)\n","\n","for lr in lrs:\n","    optimizer = Adam(model.parameters(), lr=lr,  weight_decay=weight_decay)\n","    for epoch in range(n_epochs):\n","        train_loss = 0\n","\n","        for i,data in enumerate(train_loader, 0):\n","            # extract data in this batch\n","            inputs, labels = data\n","\n","            if torch.cuda.is_available():\n","                inputs = inputs.cuda()\n","                labels = labels.cuda()\n","\n","            #Set the parameter gradients to zero\n","            optimizer.zero_grad()\n","            \n","            #Forward pass, backward pass, optimize\n","            output = model(inputs.float())\n","            loss_train = criterion(output, labels.long())\n","            loss_train.backward()\n","            optimizer.step()\n","\n","            #Print statistics\n","            train_loss += loss_train\n","\n","        train_losses.append(train_loss)   \n","        ## training accuracy\n","        with torch.no_grad():\n","            output = model(X_train.cuda().float())\n","            \n","        softmax = torch.exp(output).cpu()\n","        prob = list(softmax.numpy())\n","        predictions = np.argmax(prob, axis=1)\n","        # accuracy on training set\n","        train_acc = accuracy_score(y_train.cpu(), predictions)\n","\n","        # validation loss\n","        with torch.no_grad():\n","            output = model(X_val.cuda().float())\n","        val_loss = criterion(output, y_val.cuda().long())\n","        val_losses.append(val_loss)\n","        softmax = torch.exp(output).cpu()\n","        prob = list(softmax.numpy())\n","        predictions = np.argmax(prob, axis=1)\n","        # accuracy on validation set\n","        val_acc = accuracy_score(y_val.cpu(), predictions)\n","\n","        ## test accuracy\n","        with torch.no_grad():\n","            output = model(X_test.to(device).cuda().float())\n","        softmax = torch.exp(output).cpu()\n","        prob = list(softmax.numpy())\n","        predictions = np.argmax(prob, axis=1)\n","\n","        # accuracy on test set\n","        test_acc = accuracy_score(y_test.cpu(), predictions)\n","\n","        print(\"Epoch {}, train_loss: {:.2f}, \\t val_loss: {:.2f} \".format(\n","                    epoch+1, train_loss, val_loss))\n","        print(\"training accuracy = {:.2f}, \\t validation accuracy = {:.2f}, \\t test accuracy = {:.2f}\".format(train_acc, val_acc, test_acc))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C5P_U43BBNah","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}
